{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = './gastroenterology_dataset/data.txt'\n",
    "\n",
    "data = np.genfromtxt(filePath, delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.0000e+00, 3.0000e+00, 3.0000e+00, ..., 2.0000e+00, 2.0000e+00,\n",
       "        2.0000e+00],\n",
       "       [1.0000e+00, 2.0000e+00, 2.0000e+00, ..., 1.0000e+00, 1.0000e+00,\n",
       "        2.0000e+00],\n",
       "       [1.3812e+02, 1.2799e+02, 8.0415e+01, ..., 1.5781e+02, 9.3569e+01,\n",
       "        9.5543e+01],\n",
       "       ...,\n",
       "       [1.1377e-02, 1.1377e-02, 2.6310e-03, ..., 2.1000e-04, 1.2000e-05,\n",
       "        1.2000e-05],\n",
       "       [1.1198e-02, 1.1198e-02, 2.6100e-03, ..., 2.0600e-04, 1.1000e-05,\n",
       "        1.1000e-05],\n",
       "       [1.1131e-02, 1.1131e-02, 2.5310e-03, ..., 1.9400e-04, 1.0000e-05,\n",
       "        1.0000e-05]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# transpose data to get features in columns and samples in rows\n",
    "data_transpose = np.transpose(data)\n",
    "data_list = data_transpose.tolist()\n",
    "\n",
    "# now let's seperate data into \"White Light Frame (WL)\" and \"NBI Frame (NBI)\"\n",
    "# 1 for WL and 2 for NBI\n",
    "data_WL, data_NBI = [],[]\n",
    "for i in range(len(data_list)):\n",
    "    if data_list[i][1] == 1:\n",
    "        data_WL.append(data_list[i])\n",
    "    elif data_list[i][1] == 2:\n",
    "        data_NBI.append(data_list[i])\n",
    "\n",
    "# checking if the separation was done correctely\n",
    "print(False in [row[1]==1 for row in data_WL])  # should be False\n",
    "print(False in [row[1]==2 for row in data_NBI]) # should be False\n",
    "print((len(data_WL)+len(data_NBI))==len(data_list)) # should be True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating features and targets out of data_WL and data_NBI\n",
    "fea_WL = [row[2:] for row in data_WL]\n",
    "class_WL = [row[0] for row in data_WL]\n",
    "\n",
    "fea_NBI = [row[2:] for row in data_NBI]\n",
    "class_NBI = [row[0] for row in data_NBI]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# X -> features, y -> label\n",
    "X = np.array(fea_WL+fea_NBI)\n",
    "y = np.array(class_WL+class_NBI)\n",
    "\n",
    "similarity_matrix = cosine_similarity(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.93607026, 0.97028607, ..., 0.99687239, 0.98485682,\n",
       "        0.91366254],\n",
       "       [0.93607026, 1.        , 0.98597573, ..., 0.95746692, 0.9496139 ,\n",
       "        0.98196557],\n",
       "       [0.97028607, 0.98597573, 1.        , ..., 0.98576319, 0.96913295,\n",
       "        0.96665076],\n",
       "       ...,\n",
       "       [0.99687239, 0.95746692, 0.98576319, ..., 1.        , 0.98455307,\n",
       "        0.93653564],\n",
       "       [0.98485682, 0.9496139 , 0.96913295, ..., 0.98455307, 1.        ,\n",
       "        0.93032114],\n",
       "       [0.91366254, 0.98196557, 0.96665076, ..., 0.93653564, 0.93032114,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-69-22c8561e0f7b>:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  adj_matrix = 1/((1/similarity_matrix)-1)\n"
     ]
    }
   ],
   "source": [
    "adj_matrix = 1/((1/similarity_matrix)-1)\n",
    "np.fill_diagonal(adj_matrix, 0)\n",
    "adj_matrix[adj_matrix <= np.mean(adj_matrix[adj_matrix != np.min(adj_matrix)])] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1454"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2879.9687071143035\n",
      "82.38514782992013\n"
     ]
    }
   ],
   "source": [
    "print(np.max(adj_matrix))\n",
    "print(np.min(adj_matrix[adj_matrix != np.min(adj_matrix)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "\n",
    "# # create nx graph from sim matrix\n",
    "# G = nx.to_networkx_graph(similarity_matrix)\n",
    "\n",
    "# nx.draw(G,with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=4)\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "kernel_pca = KernelPCA(\n",
    "    n_components=4, kernel=\"linear\", gamma=10, fit_inverse_transform=True, alpha=0.1\n",
    ")\n",
    "\n",
    "X_kpca = kernel_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 4)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_kpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA(n_components=2)\n",
    "X_lda = lda.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  1.9239266259901187\n",
      "max =  3.9999399648203853\n",
      "min =  1.4407206584854393e-05\n",
      "4986\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "X_normalized = preprocessing.normalize(X_kpca, norm='l2')\n",
    "euclidean_dist = euclidean_distances(X_normalized)\n",
    "squared_euclidean = np.square(euclidean_dist)\n",
    "\n",
    "# adj_matrix = 10**(1/similarity_matrix)\n",
    "adj_matrix = squared_euclidean\n",
    "np.fill_diagonal(adj_matrix, 0)\n",
    "print('mean = ', np.mean(adj_matrix[adj_matrix != np.min(adj_matrix)]))\n",
    "print('max = ', np.max(adj_matrix))\n",
    "print('min = ', np.min(adj_matrix[adj_matrix != np.min(adj_matrix)]))\n",
    "adj_matrix[adj_matrix >= -1.85+np.mean(adj_matrix[adj_matrix != np.min(adj_matrix)])] = 0\n",
    "print(np.count_nonzero(adj_matrix))\n",
    "\n",
    "\n",
    "G = nx.from_numpy_matrix(adj_matrix, create_using=nx.MultiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G.remove_nodes_from(list(nx.isolates(G)))\n",
    "\n",
    "color_map = []\n",
    "for i in range(len(G)):\n",
    "    if y[i] == 1:\n",
    "        color_map.append('blue')\n",
    "    elif y[i] == 2: \n",
    "        color_map.append('green')\n",
    "    elif y[i] == 3: \n",
    "        color_map.append('red')\n",
    "\n",
    "nx.draw_networkx(G, pos=nx.spring_layout(G), node_size=20, node_color=color_map, linewidths=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5e9bb5c8109d9c89e3540dfae7ab7a0527331017fc9eeaf677245afa113f1a5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
